{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OF6Jp0V7fdcy"
      },
      "source": [
        "# IMPORTAÇÕES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xxt8SNg1blW5"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import string\n",
        "import random\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0VSNFyTfjSk"
      },
      "source": [
        "# DICIONÁRIOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unby51MRfBOD"
      },
      "outputs": [],
      "source": [
        "# Dicionário 01\n",
        "data = {\"intents\": [\n",
        "    {\"tag\": \"greeting1\",\n",
        "    \"patterns\": [\"Oi\", \"Olá\", \"E aí\", \"Ei\", \"Opa\", \"Bom dia\", \"Boa tarde\", \"Boa noite\"],\n",
        "    \"responses\": [\"Olá\", \"Opa\", \"E aí\", \"Oi\", \"Ei\"],\n",
        "    },\n",
        "    {\"tag\": \"greeting2\",\n",
        "    \"patterns\": [\"Como vai você\", \"Você está bem\", \"Tudo bem\", \"Como vai a vida\", \"Tudo certo\", \"De boa\", \"Tranquilo\", \"Beleza\"],\n",
        "    \"responses\": [\"Bem e você?\", \"Tudo maravilha\", \"Muito melhor agora\", \"Tudo ok\", \"Tudo mais ou menos\"],\n",
        "    },\n",
        "\t{\"tag\": \"question1\",\n",
        "    \"patterns\": [\"por que você existe\", \"por que você foi criado\", \"qual seu propósito\"],\n",
        "    \"responses\": [\"Eu fui criado para fins didáticos, faço parte de um TGI criado por alunos da UNICSUL no ano de 2022.\"],\n",
        "    },\n",
        "\t{\"tag\": \"question2\",\n",
        "    \"patterns\": [\"o que você gosta de fazer\", \"gosta de fazer o que\", \"o que você curte fazer\"],\n",
        "    \"responses\": [\"Eu gosto de aprender coisas novas\", \"Gosto de estudar\", \"Gosto de adquirir conhecimento\", \"Gosto de aprender palavras\"],\n",
        "    },\n",
        "    {\"tag\": \"age\",\n",
        "    \"patterns\": [\"Você tem quantos anos?\", \"Quantos anos você tem?\", \"Quando é seu aniversário?\", \"Quando você nasceu?\"],\n",
        "    \"responses\": [\"Eu tenho 0 anos\", \"Eu nasci em 2022\", \"Meu aniversário é um Julho\", \"Faço 1 ano em Julho de 2023\", \"Eu nasci este ano\"],\n",
        "    },\n",
        "    {\"tag\": \"date\",\n",
        "    \"patterns\": [\"Tem planos para o fim de semana?\", \"O que você vai faz no tempo livre\", \"Vai fazer o que neste fim de semana?\", \"Vai fazer algo neste fim de semana?\"],\n",
        "    \"responses\": [\"Não tenho nada pra fazer\", \"Eu estarei ocupado\", \"Vou dormir o dia todo\", \"Vou descansar\", \"Vou ver um filme\", \"Vou estudar\", \"Vou ficar assistindo série\"],\n",
        "    },\n",
        "    {\"tag\": \"name\",\n",
        "    \"patterns\": [\"Qual o seu nome?\", \"Você tem um nome?\", \"Qual seu apelido?\", \"Quem é você?\", \"Como você se chama?\"],\n",
        "    \"responses\": [\"Ainda não tenho nome\", \"Ainda estou escolhendo meu nome\", \"Eu ainda não tenho\"],\n",
        "    },\n",
        "    {\"tag\": \"goodbye\",\n",
        "    \"patterns\": [\"até mais\", \"tchau\", \"obrigado\", \"adeus\", \"tenho que ir\", \"te vejo depois\", \"estou indo\"],\n",
        "    \"responses\": [\"Foi ótimo falar com você\", \"Nos vemos depois\", \"Espero te ver novamente\", \"Até logo\", \"Nos vemos em breve\"],\n",
        "    }\n",
        "]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PxvDU7Y0OOP"
      },
      "outputs": [],
      "source": [
        "# Dicionário 02\n",
        "'''data = {\"intents\": [\n",
        "    {\"tag\": \"greeting\",\n",
        "    \"patterns\": [\"Oi\", \"Olá\", \"E aí\", \"Ei\", \"Bom dia\", \"Boa tarde\", \"Boa noite\"],\n",
        "    \"responses\": [\"Olá, eu sou o assistente virtual dessa plataforma, estou aqui para te auxiliar da melhor forma possível, neste momento eu ainda estou em fase de aprendizado, então me diga em poucas palavras, com o que eu posso te ajudar?\"],\n",
        "    },\n",
        "    {\"tag\": \"question1\",\n",
        "    \"patterns\": [\"rematrícula\"],\n",
        "    \"responses\": [\"Ainda não estamos em período de rematrícula, você pode tentar novamente entre os dias x e y\"],\n",
        "    },\n",
        "    {\"tag\": \"question2\",\n",
        "    \"patterns\": [\"notas\"],\n",
        "    \"responses\": [\"Vamos lá, para consultar suas notas basta entrar na área do aluno, acessar o menu 'Vida Acadêmica' e clicar em 'Minhas Notas'\"],\n",
        "    },\n",
        "    {\"tag\": \"question3\",\n",
        "    \"patterns\": [\"mensalidade\"],\n",
        "    \"responses\": [\"Para pagar sua mensalidade basta entrar na área do aluno, acessar o menu 'Pagar Mensalidade' e escolher o boleto do mês atual\"],\n",
        "    },\n",
        "    {\"tag\": \"question4\",\n",
        "    \"patterns\": [\"Falar com atendente\", \"Quero falar com alguém\", \"Falar com pessoa\", \"Falar com humano\"],\n",
        "    \"responses\": [\"Vou te transferir para o atendimento humanizado, espero que tenha te ajudado até o momento, até mais!\"],\n",
        "    },\n",
        "    {\"tag\": \"goodbye\",\n",
        "    \"patterns\": [\"encerrar conversa\"],\n",
        "    \"responses\": [\"Espero ter ajudado, muito obrigado pelo contato e até mais!\"],\n",
        "    }\n",
        "]}'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3psZEjmG0OOQ"
      },
      "outputs": [],
      "source": [
        "# Dicionário 03\n",
        "'''data = {\"intents\": [\n",
        "    {\"tag\": \"greeting\",\n",
        "    \"patterns\": [\"Oi\", \"Olá\", \"E aí\", \"Ei\", \"Bom dia\", \"Boa tarde\", \"Boa noite\"],\n",
        "    \"responses\": [\"Olá, eu sou o assistente virtual dessa plataforma, estou aqui para te auxiliar da melhor forma possível, neste momento eu ainda estou em fase de aprendizado, então me diga em poucas palavras, com o que eu posso te ajudar?\"],\n",
        "    },\n",
        "    {\"tag\": \"prazo\",\n",
        "    \"patterns\": [\"Quanto tempo leva para chegar a encomenda\", \"Quando chega a encomenda\", \"qual o prazo de entrega\"],\n",
        "    \"responses\": [\"Nosso prazo de entrega é de 15 a 20 dias depois da realização do pedido.\"],\n",
        "    },\n",
        "    {\"tag\": \"entrega\",\n",
        "    \"patterns\": [\"região\", \"regiões\", \"onde entrega\"],\n",
        "    \"responses\": [\"Neste momento entregamos apenas para a região Sudeste do Brasil.\", \"Nossa loja entrega apenas na região Sudeste do Brasil.\"],\n",
        "    },\n",
        "    {\"tag\": \"funcionamento\",\n",
        "    \"patterns\": [\"horário de funcionamento\", \"que horas abre\", \"que horas fecha\", \"que horas está aberta\", \"funciona em qual horário\"],\n",
        "    \"responses\": [\"Nosso horário de funcionamento da loja física é das x às y.\"],\n",
        "    },\n",
        "    {\"tag\": \"localizacao\",\n",
        "    \"patterns\": [\"onde fica\", \"qual o local\", \"qual a localização\", \"qual cidade\", \"qual estado\"],\n",
        "    \"responses\": [\"Atualmente estamos localizados no endereço Av. Paulista, 0000 - Bela Vista, São Paulo - SP\"],\n",
        "    },\n",
        "    {\"tag\": \"goodbye\",\n",
        "    \"patterns\": [\"encerrar conversa\"],\n",
        "    \"responses\": [\"Espero ter ajudado, muito obrigado pelo contato e até mais!\"],\n",
        "    }\n",
        "]}'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXdhJlpVfnLz"
      },
      "source": [
        "# LÓGICA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPnXCDxb0OOS"
      },
      "outputs": [],
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1SigBfIb7yz"
      },
      "outputs": [],
      "source": [
        "words = []\n",
        "classes = []\n",
        "doc_x = []\n",
        "doc_y = []\n",
        "\n",
        "for intent in data[\"intents\"]:\n",
        "    for pattern in intent[\"patterns\"]:\n",
        "        tokens = nltk.word_tokenize(pattern)\n",
        "        words.extend(tokens)\n",
        "        doc_x.append(pattern)\n",
        "        doc_y.append(intent[\"tag\"])\n",
        "        \n",
        "        # adicionar a tag às classes se ainda não estiver lá\n",
        "        if intent[\"tag\"] not in classes:\n",
        "            classes.append(intent[\"tag\"])\n",
        "\n",
        "words = [lemmatizer.lemmatize(word.lower()) for word in words if word not in string.punctuation]\n",
        "\n",
        "words = sorted(set(words))\n",
        "classes = sorted(set(classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR5aQAnEmCh5"
      },
      "source": [
        "# TREINAMENTO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17e12sdVcCkZ"
      },
      "outputs": [],
      "source": [
        "training = []\n",
        "out_empty = [0] * len(classes)\n",
        "\n",
        "for idx, doc in enumerate(doc_x):\n",
        "    bow = []\n",
        "    text = lemmatizer.lemmatize(doc.lower())\n",
        "    for word in words:\n",
        "        bow.append(1) if word in text else bow.append(0)\n",
        "\n",
        "    output_row = list(out_empty)\n",
        "    output_row[classes.index(doc_y[idx])] = 1 #antigo out_empty[classes.index(doc_y[idx])] = 1\n",
        "\n",
        "    training.append([bow, output_row])\n",
        "\n",
        "random.shuffle(training)\n",
        "training = np.array(training, dtype=object)\n",
        "\n",
        "train_x = np.array(list(training[:, 0]))\n",
        "train_y = np.array(list(training[:, 1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBaEC82AmeKg"
      },
      "source": [
        "# MODELO DE DEEP LEARNING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFx6AWd-cEGx"
      },
      "outputs": [],
      "source": [
        "input_shape = (len(train_x[0]),)\n",
        "output_shape = len(train_y[0])\n",
        "epochs = 200\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=input_shape, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation=\"relu\"))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(output_shape, activation = \"softmax\"))\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.01, decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=adam,\n",
        "                metrics=[\"accuracy\"])\n",
        "print(model.summary())\n",
        "model.fit(x=train_x, y=train_y, epochs=200, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v2pR6H-emzAJ"
      },
      "source": [
        "# PREPARAR TEXTO E PREVER A MENSAGEM DE SAÍDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Im5weZ82cFsJ"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    return tokens\n",
        "\n",
        "def bag_of_words(text, vocab):\n",
        "    tokens = clean_text(text)\n",
        "    bow = [0] * len(vocab)\n",
        "    for w in tokens:\n",
        "        for idx, word in enumerate(vocab):\n",
        "            if word == w:\n",
        "                bow[idx] = 1\n",
        "    return np.array(bow)\n",
        "\n",
        "def pred_class(text, vocab, labels):\n",
        "    bow = bag_of_words(text, vocab)\n",
        "    result = model.predict(np.array([bow]))[0]\n",
        "    tresh = 0.2\n",
        "    y_pred = [[idx, res] for idx, res in enumerate(result) if res > tresh]\n",
        "\n",
        "    y_pred.sort(key=lambda x: x[1], reverse=True)\n",
        "    return_list = []\n",
        "    for r in y_pred:\n",
        "        return_list.append(labels[r[0]])\n",
        "    return return_list\n",
        "\n",
        "def get_response(intents_list, intents_json):\n",
        "    tag = intents_list[0]\n",
        "    list_of_intents = intents_json[\"intents\"]\n",
        "    for i in list_of_intents:\n",
        "        if i[\"tag\"] == tag:\n",
        "            result = random.choice(i[\"responses\"])\n",
        "            break\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsMEbJFeftBi"
      },
      "source": [
        "# EXECUÇÃO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qU1sVjWcHpq"
      },
      "outputs": [],
      "source": [
        "def exec(messageInput):\n",
        "    message = str(messageInput)\n",
        "    intents = pred_class(message, words, classes)\n",
        "    result = get_response(intents, data)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUdRKXYo0v42"
      },
      "source": [
        "# API (Telegram)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mYM1IeR0xxY",
        "outputId": "f03f32ac-ff76-418a-8fc2-c8b5b2709918"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytelegrambotapi\n",
            "  Downloading pyTelegramBotAPI-4.8.0.tar.gz (217 kB)\n",
            "\u001b[K     |████████████████████████████████| 217 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from pytelegrambotapi) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->pytelegrambotapi) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->pytelegrambotapi) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->pytelegrambotapi) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->pytelegrambotapi) (3.0.4)\n",
            "Building wheels for collected packages: pytelegrambotapi\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-4.8.0-py3-none-any.whl size=200125 sha256=3ecd769a42008f38d1df7e6636bc91e5535fb22121df07730d285995d67eb7be\n",
            "  Stored in directory: /root/.cache/pip/wheels/c2/05/70/8409792e663e67a70e057df1f18d070105c1c457b3f410bbb0\n",
            "Successfully built pytelegrambotapi\n",
            "Installing collected packages: pytelegrambotapi\n",
            "Successfully installed pytelegrambotapi-4.8.0\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n"
          ]
        }
      ],
      "source": [
        "!pip install pytelegrambotapi\n",
        "\n",
        "import telebot\n",
        "\n",
        "CHAVE_API = \"5960765979:AAG_pqUkd4wUDN2qYWlfOIlbcoLFfisXBok\"\n",
        "\n",
        "bot = telebot.TeleBot(CHAVE_API)\n",
        "\n",
        "@bot.message_handler(commands=['start', 'help'])\n",
        "def handle_start_help(message):\n",
        "\tpass\n",
        "\n",
        "@bot.message_handler(content_types=['document', 'audio'])\n",
        "def handle_docs_audio(message):\n",
        "\tpass\n",
        "\n",
        "@bot.message_handler(content_types=['text'])\n",
        "def saudacoes(mensagem):\n",
        "    result = exec(mensagem)\n",
        "    bot.send_message(mensagem.chat.id, result)\n",
        "\n",
        "bot.polling()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MID86V9QFk2"
      },
      "source": [
        "# API (Whatsapp)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}