# -*- coding: utf-8 -*-
"""tgi_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1aYyJ32ZTcqBV2Xp3t34F4MTsBlVNgdUK

# IMPORTAÇÕES
"""

import json
import string
import random
import nltk
import numpy as np
from nltk.stem import WordNetLemmatizer
import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Dropout

nltk.download('omw-1.4')
nltk.download("punkt")
nltk.download("wordnet")

"""# DICIONÁRIOS"""

# Dicionário 01
data = {"intents": [
    {"tag": "greeting1",
    "patterns": ["Oi", "Olá", "E aí", "Ei", "Opa", "Bom dia", "Boa tarde", "Boa noite"],
    "responses": ["Olá", "Opa", "E aí", "Oi", "Ei"],
    },
    {"tag": "greeting2",
    "patterns": ["Como vai você", "Você está bem", "Tudo bem", "Como vai a vida", "Tudo certo", "De boa", "Tranquilo", "Beleza"],
    "responses": ["Bem e você?", "Tudo maravilha", "Muito melhor agora", "Tudo ok", "Tudo mais ou menos"],
    },
	{"tag": "question1",
    "patterns": ["por que você existe", "por que você foi criado", "qual seu propósito"],
    "responses": ["Eu fui criado para fins didáticos, faço parte de um TGI criado por alunos da UNICSUL no ano de 2022."],
    },
	{"tag": "question2",
    "patterns": ["o que você gosta de fazer", "gosta de fazer o que", "o que você curte fazer"],
    "responses": ["Eu gosto de aprender coisas novas", "Gosto de estudar", "Gosto de adquirir conhecimento", "Gosto de aprender palavras"],
    },
    {"tag": "age",
    "patterns": ["Você tem quantos anos?", "Quantos anos você tem?", "Quando é seu aniversário?", "Quando você nasceu?"],
    "responses": ["Eu tenho 0 anos", "Eu nasci em 2022", "Meu aniversário é um Julho", "Faço 1 ano em Julho de 2023", "Eu nasci este ano"],
    },
    {"tag": "date",
    "patterns": ["Tem planos para o fim de semana?", "O que você vai faz no tempo livre", "Vai fazer o que neste fim de semana?", "Vai fazer algo neste fim de semana?"],
    "responses": ["Não tenho nada pra fazer", "Eu estarei ocupado", "Vou dormir o dia todo", "Vou descansar", "Vou ver um filme", "Vou estudar", "Vou ficar assistindo série"],
    },
    {"tag": "name",
    "patterns": ["Qual o seu nome?", "Você tem um nome?", "Qual seu apelido?", "Quem é você?", "Como você se chama?"],
    "responses": ["Ainda não tenho nome", "Ainda estou escolhendo meu nome", "Eu ainda não tenho"],
    },
    {"tag": "goodbye",
    "patterns": ["até mais", "tchau", "obrigado", "adeus", "tenho que ir", "te vejo depois", "estou indo"],
    "responses": ["Foi ótimo falar com você", "Nos vemos depois", "Espero te ver novamente", "Até logo", "Nos vemos em breve"],
    }
]}

# Dicionário 02
'''data = {"intents": [
    {"tag": "greeting",
    "patterns": ["Oi", "Olá", "E aí", "Ei", "Bom dia", "Boa tarde", "Boa noite"],
    "responses": ["Olá, eu sou o assistente virtual dessa plataforma, estou aqui para te auxiliar da melhor forma possível, neste momento eu ainda estou em fase de aprendizado, então me diga em poucas palavras, com o que eu posso te ajudar?"],
    },
    {"tag": "question1",
    "patterns": ["rematrícula"],
    "responses": ["Ainda não estamos em período de rematrícula, você pode tentar novamente entre os dias x e y"],
    },
    {"tag": "question2",
    "patterns": ["notas"],
    "responses": ["Vamos lá, para consultar suas notas basta entrar na área do aluno, acessar o menu 'Vida Acadêmica' e clicar em 'Minhas Notas'"],
    },
    {"tag": "question3",
    "patterns": ["mensalidade"],
    "responses": ["Para pagar sua mensalidade basta entrar na área do aluno, acessar o menu 'Pagar Mensalidade' e escolher o boleto do mês atual"],
    },
    {"tag": "question4",
    "patterns": ["Falar com atendente", "Quero falar com alguém", "Falar com pessoa", "Falar com humano"],
    "responses": ["Vou te transferir para o atendimento humanizado, espero que tenha te ajudado até o momento, até mais!"],
    },
    {"tag": "goodbye",
    "patterns": ["encerrar conversa"],
    "responses": ["Espero ter ajudado, muito obrigado pelo contato e até mais!"],
    }
]}'''

# Dicionário 03
'''data = {"intents": [
    {"tag": "greeting",
    "patterns": ["Oi", "Olá", "E aí", "Ei", "Bom dia", "Boa tarde", "Boa noite"],
    "responses": ["Olá, eu sou o assistente virtual dessa plataforma, estou aqui para te auxiliar da melhor forma possível, neste momento eu ainda estou em fase de aprendizado, então me diga em poucas palavras, com o que eu posso te ajudar?"],
    },
    {"tag": "prazo",
    "patterns": ["Quanto tempo leva para chegar a encomenda", "Quando chega a encomenda", "qual o prazo de entrega"],
    "responses": ["Nosso prazo de entrega é de 15 a 20 dias depois da realização do pedido."],
    },
    {"tag": "entrega",
    "patterns": ["região", "regiões", "onde entrega"],
    "responses": ["Neste momento entregamos apenas para a região Sudeste do Brasil.", "Nossa loja entrega apenas na região Sudeste do Brasil."],
    },
    {"tag": "funcionamento",
    "patterns": ["horário de funcionamento", "que horas abre", "que horas fecha", "que horas está aberta", "funciona em qual horário"],
    "responses": ["Nosso horário de funcionamento da loja física é das x às y."],
    },
    {"tag": "localizacao",
    "patterns": ["onde fica", "qual o local", "qual a localização", "qual cidade", "qual estado"],
    "responses": ["Atualmente estamos localizados no endereço Av. Paulista, 0000 - Bela Vista, São Paulo - SP"],
    },
    {"tag": "goodbye",
    "patterns": ["encerrar conversa"],
    "responses": ["Espero ter ajudado, muito obrigado pelo contato e até mais!"],
    }
]}'''

"""# LÓGICA"""

lemmatizer = WordNetLemmatizer()

words = []
classes = []
doc_x = []
doc_y = []

for intent in data["intents"]:
    for pattern in intent["patterns"]:
        tokens = nltk.word_tokenize(pattern)
        words.extend(tokens)
        doc_x.append(pattern)
        doc_y.append(intent["tag"])
        
        # adicionar a tag às classes se ainda não estiver lá
        if intent["tag"] not in classes:
            classes.append(intent["tag"])

words = [lemmatizer.lemmatize(word.lower()) for word in words if word not in string.punctuation]

words = sorted(set(words))
classes = sorted(set(classes))

"""# TREINAMENTO"""

training = []
out_empty = [0] * len(classes)

for idx, doc in enumerate(doc_x):
    bow = []
    text = lemmatizer.lemmatize(doc.lower())
    for word in words:
        bow.append(1) if word in text else bow.append(0)

    output_row = list(out_empty)
    output_row[classes.index(doc_y[idx])] = 1 #antigo out_empty[classes.index(doc_y[idx])] = 1

    training.append([bow, output_row])

random.shuffle(training)
training = np.array(training, dtype=object)

train_x = np.array(list(training[:, 0]))
train_y = np.array(list(training[:, 1]))

"""# MODELO DE DEEP LEARNING"""

input_shape = (len(train_x[0]),)
output_shape = len(train_y[0])
epochs = 200

model = Sequential()
model.add(Dense(128, input_shape=input_shape, activation="relu"))
model.add(Dropout(0.5))
model.add(Dense(64, activation="relu"))
model.add(Dropout(0.3))
model.add(Dense(output_shape, activation = "softmax"))
adam = tf.keras.optimizers.Adam(learning_rate=0.01, decay=1e-6)
model.compile(loss='categorical_crossentropy',
                optimizer=adam,
                metrics=["accuracy"])
print(model.summary())
model.fit(x=train_x, y=train_y, epochs=200, verbose=1)

"""# PREPARAR TEXTO E PREVER A MENSAGEM DE SAÍDA"""

def clean_text(text):
    tokens = nltk.word_tokenize(text)
    tokens = [lemmatizer.lemmatize(word) for word in tokens]
    return tokens

def bag_of_words(text, vocab):
    tokens = clean_text(text)
    bow = [0] * len(vocab)
    for w in tokens:
        for idx, word in enumerate(vocab):
            if word == w:
                bow[idx] = 1
    return np.array(bow)

def pred_class(text, vocab, labels):
    bow = bag_of_words(text, vocab)
    result = model.predict(np.array([bow]))[0]
    tresh = 0.2
    y_pred = [[idx, res] for idx, res in enumerate(result) if res > tresh]

    y_pred.sort(key=lambda x: x[1], reverse=True)
    return_list = []
    for r in y_pred:
        return_list.append(labels[r[0]])
    return return_list

def get_response(intents_list, intents_json):
    tag = intents_list[0]
    list_of_intents = intents_json["intents"]
    for i in list_of_intents:
        if i["tag"] == tag:
            result = random.choice(i["responses"])
            break
    return result

"""# EXECUÇÃO"""

def exec(messageInput):
    message = str(messageInput)
    intents = pred_class(message, words, classes)
    result = get_response(intents, data)
    return result

"""# API (Telegram)


"""

!pip install pytelegrambotapi

import telebot

CHAVE_API = "5960765979:AAG_pqUkd4wUDN2qYWlfOIlbcoLFfisXBok"

bot = telebot.TeleBot(CHAVE_API)

@bot.message_handler(commands=['start', 'help'])
def handle_start_help(message):
	pass

@bot.message_handler(content_types=['document', 'audio'])
def handle_docs_audio(message):
	pass

@bot.message_handler(content_types=['text'])
def saudacoes(mensagem):
    result = exec(mensagem)
    bot.send_message(mensagem.chat.id, result)

bot.polling()

"""# API (Whatsapp)


"""